{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy, deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.append('../input/coderepro')\n",
    "from method4memreducing import get_dcode_mapping, get_dcode_and_ldcode\n",
    "from select_samples import extract_tran4feat, extract_tran4ibcf\n",
    "from sample_method import generate_samples4finedrank_direct, generate_samples4infer, generate_samples_feature4finedrank\n",
    "from select_features import get_mv_for_features, get_importance_from_tree\n",
    "from recall_phrase.merge_multi_method import get_recall_by_ibcf_and_majority\n",
    "from feature_engineer.article_features import extract_arr_features\n",
    "from feature_engineer.customer_features import extract_apk_features\n",
    "from feature_engineer.interacting_features import extract_historical_purchased_items\n",
    "from model import train_tree_model\n",
    "from recall_phrase.item_base_cf.recall import get_customer_purchasing_items\n",
    "from method4infer import pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_train_csv = '../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv'\n",
    "transactions = pd.read_csv(transactions_train_csv, dtype={'article_id': str})\n",
    "transactions['customer_id'] = transactions['customer_id'].apply(lambda x: int(x[-16:],16) ).astype('int64')\n",
    "transactions['article_id'] = transactions['article_id'].astype('int32')\n",
    "transactions['t_dat_dateform'] = pd.to_datetime(transactions['t_dat'])\n",
    "\n",
    "\n",
    "article_csv = '../input/h-and-m-personalized-fashion-recommendations/articles.csv'\n",
    "article = pd.read_csv(article_csv)\n",
    "article['article_id'] = article['article_id'].astype('int32')\n",
    "\n",
    "\n",
    "customer_csv = '../input/h-and-m-personalized-fashion-recommendations/customers.csv'\n",
    "customer = pd.read_csv(customer_csv)\n",
    "customer['customer_id'] = customer['customer_id'].apply(lambda x: int(x[-16:],16) ).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2c_mapping, c2d_mapping = get_dcode_mapping(transactions['t_dat_dateform'])\n",
    "transactions = get_dcode_and_ldcode(transactions, d2c_mapping)\n",
    "\n",
    "'''\n",
    "get transaction for feature, model and recall for training model part\n",
    "'''\n",
    "# ld4feat_trn_cv = '2020-09-08'\n",
    "# ld4ibcf_trn_cv = '2020-09-08'\n",
    "# tran4feat_trn_cv, tran4model_trn_cv = extract_tran4feat(\n",
    "#         transactions,\n",
    "#         ld4feat_trn_cv,\n",
    "#         d2c_mapping,\n",
    "#         tran4feat_sessions=28,\n",
    "#         is_tran4model=True,\n",
    "# )\n",
    "# tran4ibcf_trn_cv = extract_tran4ibcf(\n",
    "#     transactions,\n",
    "#     ld4ibcf_trn_cv,\n",
    "#     d2c_mapping,\n",
    "#     tran4ibcf_sessions=21,\n",
    "# )\n",
    "\n",
    "\n",
    "ld4feat_trn_lb = '2020-09-15'\n",
    "ld4ibcf_trn_lb = '2020-09-15'\n",
    "tran4feat_trn_lb, tran4model_trn_lb = extract_tran4feat(\n",
    "        transactions,\n",
    "        ld4feat_trn_lb,\n",
    "        d2c_mapping,\n",
    "        tran4feat_sessions=28,\n",
    "        is_tran4model=True,\n",
    ")\n",
    "tran4ibcf_trn_lb = extract_tran4ibcf(\n",
    "    transactions,\n",
    "    ld4ibcf_trn_lb,\n",
    "    d2c_mapping,\n",
    "    tran4ibcf_sessions=21,\n",
    ")\n",
    "\n",
    "\n",
    "'''\n",
    "get transaction for feature, model and recall for inferring part\n",
    "'''\n",
    "# ld4feat_dev_cv = '2020-09-15'\n",
    "# tran4feat_dev_cv, tran4model_dev_cv = extract_tran4feat(\n",
    "#         transactions,\n",
    "#         ld4feat_dev_cv,\n",
    "#         d2c_mapping,\n",
    "#         tran4feat_sessions=28,\n",
    "#         is_tran4model=True,\n",
    "# )\n",
    "ld4feat_inf_lb = '2020-09-22'\n",
    "tran4feat_inf_lb, _ = extract_tran4feat(\n",
    "        transactions,\n",
    "        ld4feat_inf_lb,\n",
    "        d2c_mapping,\n",
    "        tran4feat_sessions=28,\n",
    "        is_tran4model=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get recall items for training and dev in cv\n",
    "'''\n",
    "# W4ibcf_trn_cv, cpi4recall_trn_cv = get_recall_by_ibcf_and_majority(tran4ibcf_trn_cv)\n",
    "# W4ibcf_dev_cv, cpi4recall_dev_cv = get_recall_by_ibcf_and_majority(tran4ibcf_dev_cv)\n",
    "\n",
    "\n",
    "'''\n",
    "get recall items for training and inference in lb\n",
    "'''\n",
    "W4ibcf_trn_lb, cpi4recall_trn_lb = get_recall_by_ibcf_and_majority(tran4ibcf_trn_lb)\n",
    "W4ibcf_inf_lb, cpi4recall_inf_lb = get_recall_by_ibcf_and_majority(tran4ibcf_inf_lb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "generate training samples\n",
    "'''\n",
    "# samples4finedrank_trn_cv = generate_samples4finedrank_direct(recall_and_purchased_trn_cv)\n",
    "samples4finedrank_trn_lb = generate_samples4finedrank_direct(recall_and_purchased_trn_lb)\n",
    "\n",
    "\n",
    "'''\n",
    "generate inferring samples\n",
    "'''\n",
    "# purchased_items_dev_cv = get_customer_purchasing_items(tran4model_dev_cv)\n",
    "# recall_and_purchased_dev_cv = combine_recall_and_purchasing_items_nw(\n",
    "#     cpi4recall_dev_cv,\n",
    "#     purchased_items_dev_cv,\n",
    "#     majority_dev_cv\n",
    "# )\n",
    "recall_inf_lb = generate_samples4infer(customer, cpi4recall_inf_lb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build feature dict for training set in local cross validation\n",
    "\n",
    "# a_features_trn_cv = extract_arr_features(article, tran4feat_trn_cv, na_filler=-1) # it is a dataframe\n",
    "# a_features_trn_cv = convert_df2dict(a_features_trn_cv, 'article_id')  # convert dataframe to dict\n",
    "\n",
    "# c_features_trn_cv = extract_apk_features(customer, tran4feat_trn_cv, na_filler=-1)\n",
    "# c_features_trn_cv = convert_df2dict(c_features_trn_cv, 'customer_id') \n",
    "\n",
    "# historical_purchasing_infor_trn_cv = extract_historical_purchased_items(tran4feat_trn_cv)\n",
    "\n",
    "\n",
    "# build feature dict for dev set in local cross validation\n",
    "# a_features_dev_cv = extract_arr_features(article, tran4feat_dev_cv, na_filler=-1)\n",
    "# a_features_dev_cv = convert_df2dict(a_features_dev_cv, 'article_id')\n",
    "\n",
    "# c_features_dev_cv = extract_apk_features(customer, tran4feat_dev_cv, na_filler=-1)\n",
    "# c_features_dev_cv = convert_df2dict(c_features_dev_cv, 'customer_id') \n",
    "\n",
    "# historical_purchasing_infor_dev_cv = extract_historical_purchased_items(tran4feat_dev_cv)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # build feature dict for training set in leading board\n",
    "a_features_trn_lb = extract_arr_features(article, tran4feat_trn_lb, na_filler=-1)\n",
    "a_features_trn_lb = convert_df2dict(a_features_trn_lb, 'article_id')\n",
    "\n",
    "c_features_trn_lb = extract_apk_features(customer, tran4feat_trn_lb, na_filler=-1)\n",
    "c_features_trn_lb = convert_df2dict(c_features_trn_lb, 'customer_id') \n",
    "\n",
    "historical_purchasing_infor_trn_lb = extract_historical_purchased_items(tran4feat_trn_lb)\n",
    "\n",
    "\n",
    "# # build feature dict for inferring set in leading board\n",
    "a_features_inf_lb = extract_arr_features(article, tran4feat_inf_lb, na_filler=-1)\n",
    "a_features_inf_lb = convert_df2dict(a_features_inf_lb, 'article_id')\n",
    "\n",
    "c_features_inf_lb = extract_apk_features(customer, tran4feat_inf_lb, na_filler=-1)\n",
    "c_features_inf_lb = convert_df2dict(c_features_inf_lb, 'customer_id') \n",
    "\n",
    "historical_purchasing_infor_inf_lb = extract_historical_purchased_items(tran4feat_inf_lb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_feature4finedrank_trn_lb = generate_samples_feature4finedrank(\n",
    "    samples4finedrank_trn_lb,\n",
    "    a_features_trn_lb,\n",
    "    c_features_trn_lb,\n",
    "    historical_purchasing_infor_trn_lb)\n",
    "\n",
    "\n",
    "# drop features are not in numeric dataform\n",
    "samples_feature4finedrank_trn_lb = samples_feature4finedrank_trn_lb.drop(\n",
    "    ['club_member_status', 'fashion_news_frequency', 'postal_code'], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "select features\n",
    "'''\n",
    "\n",
    "# by mv test\n",
    "# mv_for_features = get_mv_for_features(\n",
    "#     data=samples_feature4finedrank_trn_cv,\n",
    "#     label='label' \n",
    "# )\n",
    "\n",
    "mv_for_features = get_mv_for_features(\n",
    "    data=samples_feature4finedrank_trn_lb,\n",
    "    label='label' \n",
    ")\n",
    "\n",
    "selected_features_from_mv = []\n",
    "for feature, info in mv_for_features.items():\n",
    "    if info['p-value'][1] <= 0.05:\n",
    "        selected_features_from_mv.append(feature)\n",
    "        \n",
    "\n",
    "# by tree\n",
    "# _, feature_importance_from_lgb , features_and_importance_from_lgb = get_importance_from_tree(\n",
    "#     data=samples_feature4finedrank_trn_cv,\n",
    "#     label='label',\n",
    "#     mode='lgb',\n",
    "# )\n",
    "\n",
    "_, feature_importance_from_lgb , features_and_importance_from_lgb = get_importance_from_tree(\n",
    "    data=samples_feature4finedrank_trn_lb,\n",
    "    label='label',\n",
    "    mode='lgb',\n",
    ")\n",
    "\n",
    "\n",
    "# merge\n",
    "selected_features = list(set(selected_features_from_mv) | set(selected_features_from_lgb))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prediction\n",
    "'''\n",
    "# clf = train_tree_model(\n",
    "#     data=samples_feature4finedrank_trn_cv,\n",
    "#     selected_features=selected_features,\n",
    "#     label='label',\n",
    "#     mode='lgb'\n",
    "# )\n",
    "\n",
    "clf = train_tree_model(\n",
    "    data=samples_feature4finedrank_trn_lb,\n",
    "    selected_features=selected_features,\n",
    "    label='label',\n",
    "    mode='lgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "inference\n",
    "'''\n",
    "\n",
    "# prediction_dev_cv = pred(\n",
    "#     recall_and_purchased_dev_cv,\n",
    "#     clf,\n",
    "#     a_features_dev_cv,\n",
    "#     c_features_dev_cv,\n",
    "#     historical_purchasing_infor_dev_cv,\n",
    "#     selected_features,\n",
    "# )\n",
    "\n",
    "\n",
    "# prediction_dev_cv\n",
    "\n",
    "\n",
    "prediction_inf_lb = pred(\n",
    "    recall_inf_lb,\n",
    "    clf,\n",
    "    a_features_inf_lb,\n",
    "    c_features_inf_lb,\n",
    "    historical_purchasing_infor_inf_lb,\n",
    "    selected_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "merge and submit\n",
    "'''\n",
    "sample_submission = pd.read_csv(\n",
    "    \"../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv\",   \n",
    ")\n",
    "sample_submission['customer_id2'] = sample_submission['customer_id'].apply(lambda x: int(x[-16:],16) ).astype('int64')\n",
    "\n",
    "prediction4submission = deepcopy(prediction_dev_cv)\n",
    "prediction4submission = deepcopy(prediction_inf_lb)\n",
    "prediction4submission = prediction4submission.rename(\n",
    "    columns={'customer_id': 'customer_id2'}\n",
    ")\n",
    "sample_submission = pd.merge(\n",
    "    sample_submission,\n",
    "    prediction4submission,\n",
    "    how='left',\n",
    "    on='customer_id2',\n",
    ")\n",
    "\n",
    "# 'identity' is helping field, used to drop those without prediction\n",
    "sample_submission['identity'] = sample_submission['recommend'].apply(\n",
    "    lambda x: 1 if isinstance(x, list) else 0\n",
    ")\n",
    "sample_submission = sample_submission.query('identity == 1').reset_index(drop=True)\n",
    "sample_submission = sample_submission.drop(columns=['customer_id2', 'identity'])\n",
    "\n",
    "sample_submission['recommend'] = sample_submission['recommend'].apply(\n",
    "    lambda x: ['0' + str(item) for item in x]\n",
    ")\n",
    "sample_submission = sample_submission[['customer_id', 'recommend']]\n",
    "sample_submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
